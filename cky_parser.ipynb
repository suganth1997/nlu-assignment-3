{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cky_parser.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "M4byjhNZiRjS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CKY Parser"
      ]
    },
    {
      "metadata": {
        "id": "DXW6KrXXPOs4",
        "colab_type": "code",
        "outputId": "681909dc-78d8-4997-ed9f-e4ddb5136aad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "cell_type": "code",
      "source": [
        "# Import required libraries and setup\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import treebank, ptb\n",
        "from itertools import product, accumulate\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "nltk.download('treebank')\n",
        "nltk.download('tagsets')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Package tagsets is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "cUGVhbaASP5C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Import treebank\n",
        "tree = list(treebank.parsed_sents())\n",
        "tree, test = train_test_split(tree, test_size = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aa_4WAn3i6tF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Utility functions"
      ]
    },
    {
      "metadata": {
        "id": "d1ViKHgcRmIZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def only_pos(tree):\n",
        "    to_be_deleted = []\n",
        "    for i in range(len(tree)):\n",
        "        if not isinstance(tree[i], nltk.tree.Tree):\n",
        "            continue\n",
        "        if not re.search('[a-zA-Z]', tree[i].label()):\n",
        "            to_be_deleted.append(i)\n",
        "            \n",
        "        else:\n",
        "            tree[i]._label = re.sub('-.*', '', tree[i].label())\n",
        "            only_pos(tree[i])\n",
        "            \n",
        "    for i in sorted(to_be_deleted, reverse = True):\n",
        "        tree.__delitem__(i)\n",
        "        \n",
        "def rule_count(tree, c_label):\n",
        "    target = ''\n",
        "    for t in tree:\n",
        "        if not re.search('[a-zA-Z]', t.label()):\n",
        "            continue\n",
        "            \n",
        "        if isinstance(t, nltk.tree.Tree) and isinstance(t[0], nltk.tree.Tree):\n",
        "            target += t.label() + ' '\n",
        "            #rules.append(c_label + ' --> ' + t.label())\n",
        "            rule_count(t, t.label())\n",
        "        elif isinstance(t, nltk.tree.Tree):\n",
        "            target += t.label() + ' '\n",
        "            #rules.append(c_label + ' --> ' + t.label())\n",
        "            \n",
        "    rules.append(c_label + ' --> ' + target)\n",
        "    \n",
        "def rule_count_with_words(tree, c_label):\n",
        "    target = ''\n",
        "    if isinstance(tree, str):\n",
        "        #print('I am here')\n",
        "        rules.append(c_label + ' --> ' + tree)\n",
        "        return\n",
        "    \n",
        "    for t in tree:        \n",
        "        if isinstance(t, nltk.tree.Tree) and isinstance(t[0], nltk.tree.Tree):\n",
        "            target += t.label() + ' '\n",
        "            #rules.append(c_label + ' --> ' + t.label())\n",
        "            rule_count_with_words(t, t.label())\n",
        "        elif isinstance(t, nltk.tree.Tree):\n",
        "            target += t.label() + ' '\n",
        "            rule_count_with_words(t, t.label())\n",
        "            #rules.append(c_label + ' --> ' + t.label())\n",
        "            \n",
        "        else:\n",
        "            rule_count_with_words(t, c_label)\n",
        "    \n",
        "    if target == '' or target == ' ':\n",
        "        return\n",
        "    rules.append(c_label + ' --> ' + target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TitNWWiFi_2x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Process trees"
      ]
    },
    {
      "metadata": {
        "id": "rh07Z9C0NlV8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Remove . and , \n",
        "x = [only_pos(t) for t in tree]\n",
        "x = [only_pos(t) for t in test]\n",
        "# Normal form\n",
        "x = [nltk.treetransforms.chomsky_normal_form(t) for t in tree]\n",
        "x = [nltk.treetransforms.chomsky_normal_form(t) for t in test]\n",
        "# Remove unaries\n",
        "x = [nltk.treetransforms.collapse_unary(t, collapsePOS = True) for t in tree]\n",
        "x = [nltk.treetransforms.collapse_unary(t, collapsePOS = True) for t in test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4qza5bKUjFqj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Collect Rules"
      ]
    },
    {
      "metadata": {
        "id": "khDNGk8LeFIl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_rules = []\n",
        "for i,t in enumerate(tree):\n",
        "    rules = []\n",
        "    try:\n",
        "        rule_count_with_words(t, 'S')\n",
        "        \n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    all_rules += [re.sub('[+=0-9]', '', re.sub('-[0-9]+', '', re.sub('[+][^\\s]+', '', x))) for x in rules] #Collapse ROOT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N4Y-WVxrNTqe",
        "colab_type": "code",
        "outputId": "0739dff0-1372-4267-f96f-a670683494c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "cell_type": "code",
      "source": [
        "print(all_rules[:10])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['VBP --> Do', 'NP --> you', 'VB --> make', 'NNS --> sweatshirts', 'CC --> or', 'NNS --> sparkplugs', 'NP|<CC-NNS> --> CC NNS ', 'NP --> NNS NP|<CC-NNS> ', 'VP --> VB NP ', 'SQ|<NP-VP> --> NP VP ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VNZs2RV6jZMe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Filter out leaf tags and grammar tags"
      ]
    },
    {
      "metadata": {
        "id": "Oy_5CdKkAJ16",
        "colab_type": "code",
        "outputId": "c4737bdb-71dc-44a5-c7b0-a09c942f98e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "rule_dict = [x.split(' --> ') for x in all_rules]\n",
        "\n",
        "leaf_rules = [x for x in all_rules if len(x.split(' --> ')[1].split(' ')) == 1 and x.split(' --> ')[1] != '']\n",
        "leaf_rules = [' --> '.join(x) for x in [[y.split(' --> ')[0], y.split(' --> ')[1]] for y in leaf_rules]]\n",
        "cfg_rules = [x for x in all_rules if len(x.split(' --> ')[1].split(' ')) > 1]\n",
        "cfg_rules[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NP|<CC-NNS> --> CC NNS ',\n",
              " 'NP --> NNS NP|<CC-NNS> ',\n",
              " 'VP --> VB NP ',\n",
              " 'SQ|<NP-VP> --> NP VP ',\n",
              " 'S --> VBP SQ|<NP-VP> ',\n",
              " 'NP|<JJ-NN> --> JJ NN ',\n",
              " 'NP|<DT-JJ-NN> --> DT NP|<JJ-NN> ',\n",
              " 'NP --> RB NP|<DT-JJ-NN> ',\n",
              " 'NP|<JJ-NN> --> JJ NN ',\n",
              " 'NP --> DT NP|<JJ-NN> ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "PEB_gB2SjhUZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Smoothing for unknown words"
      ]
    },
    {
      "metadata": {
        "id": "wE5xcrYJXc3d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "leaf_parent = [x.split(' --> ')[0] for x in leaf_rules if len(x.split(' --> ')[0]) != 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xlMf2DsR8VIt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "leaf_uni_prob = nltk.probability.FreqDist(leaf_parent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8sHhK7-z9urI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "denom = float(leaf_uni_prob.N())\n",
        "for word in leaf_uni_prob:\n",
        "    leaf_uni_prob[word] /= denom"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bAXRcMhbAjBT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "leaf_uni_cumu_prob = list()\n",
        "for k,v in zip(leaf_uni_prob.keys(), accumulate(leaf_uni_prob.values())):\n",
        "    leaf_uni_cumu_prob.append((k, v))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KSpetMVAjvb5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to generate rule for unknown words"
      ]
    },
    {
      "metadata": {
        "id": "jsYRV0OgEUZD",
        "colab_type": "code",
        "outputId": "7e891f2a-4fcc-4e06-d025-289eac084ce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "leaf_uni_cumu_prob = sorted(leaf_uni_cumu_prob, key = lambda x:x[1])\n",
        "\n",
        "def generate_leaf_rule():\n",
        "    rand = random.random()\n",
        "    for k, v in leaf_uni_cumu_prob:\n",
        "        if rand < v:\n",
        "            return k, leaf_uni_prob[k]\n",
        "        \n",
        "generate_leaf_rule()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('POS', 0.009538888816788445)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "OLove329Bbn6",
        "colab_type": "code",
        "outputId": "688b6f8c-ad50-4907-f2f2-1af63f0d1e6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# Vocabulary\n",
        "vocab = list(set([x.split(' --> ')[1] for x in leaf_rules]))\n",
        "vocab[:10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['longest',\n",
              " 'Traded',\n",
              " 'Aslacton',\n",
              " 'Lentjes',\n",
              " 'resignation',\n",
              " 'Elsewhere',\n",
              " 'mainframe',\n",
              " 'boogieman',\n",
              " 'cooled',\n",
              " 'tried']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "mi91A0zGkAWK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Estimate Probabilities for grammar and leaf rules"
      ]
    },
    {
      "metadata": {
        "id": "DXob_ncRO7oE",
        "colab_type": "code",
        "outputId": "a37a82bd-7208-4468-c63f-72cc6fbb0979",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "leaf_rule_prob = nltk.probability.FreqDist(leaf_rules)\n",
        "cfg_rule_prob = nltk.probability.FreqDist(cfg_rules)\n",
        "list(leaf_rule_prob.items())[:10]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('VBP --> Do', 3),\n",
              " ('NP --> you', 64),\n",
              " ('VB --> make', 54),\n",
              " ('NNS --> sweatshirts', 1),\n",
              " ('CC --> or', 268),\n",
              " ('NNS --> sparkplugs', 1),\n",
              " ('NP --> It', 89),\n",
              " (\"VBZ --> 's\", 95),\n",
              " ('RB --> not', 121),\n",
              " ('RB --> just', 16)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "TG3IWxdILPb-",
        "colab_type": "code",
        "outputId": "6f73bc46-a513-44b7-ce16-0816367b0616",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "denom_leaf = sum(leaf_rule_prob.values())\n",
        "denom_cfg = sum(cfg_rule_prob.values())\n",
        "for k in leaf_rule_prob.keys():\n",
        "    leaf_rule_prob[k] /= denom_leaf\n",
        "    \n",
        "for k in cfg_rule_prob.keys():\n",
        "    cfg_rule_prob[k] /= denom_cfg\n",
        "    \n",
        "list(leaf_rule_prob.items())[:10]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('VBP --> Do', 3.84783110586666e-05),\n",
              " ('NP --> you', 0.0008208706359182208),\n",
              " ('VB --> make', 0.0006926095990559988),\n",
              " ('NNS --> sweatshirts', 1.28261036862222e-05),\n",
              " ('CC --> or', 0.0034373957879075493),\n",
              " ('NNS --> sparkplugs', 1.28261036862222e-05),\n",
              " ('NP --> It', 0.0011415232280737758),\n",
              " (\"VBZ --> 's\", 0.0012184798501911089),\n",
              " ('RB --> not', 0.0015519585460328862),\n",
              " ('RB --> just', 0.0002052176589795552)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "8OZxT3ipkKkd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Condition probabilities for leaf rules"
      ]
    },
    {
      "metadata": {
        "id": "PFKoUIwOQF46",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i, word in enumerate(vocab):\n",
        "    collect = [x for x in leaf_rule_prob.items() if x[0].split(' --> ')[1] == word]\n",
        "    denom = sum([x[1] for x in collect])\n",
        "    for k, v in collect:\n",
        "        leaf_rule_prob[k] /= denom"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kXf-Lr-GTKuu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Lets parse"
      ]
    },
    {
      "metadata": {
        "id": "zIxO-QkEUzqf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Utility Class\n",
        "class Rule:\n",
        "    def __init__(self, rule_type, root, child_1, child_2, probability):\n",
        "        self.rule_type = rule_type\n",
        "        self.parent = root\n",
        "        self.child_1 = child_1\n",
        "        \n",
        "        if rule_type == 'NT':\n",
        "            self.child_2 = child_2\n",
        "            \n",
        "        self.prob = probability"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UKanbYDuHVTG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Debugger function\n",
        "def print_list(x):\n",
        "    for a in x:\n",
        "        print(a)\n",
        "\n",
        "y = [[[] for x in range(y+1)] for y in range(4)]\n",
        "\n",
        "#print_list(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n-oFDihZkrGQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to permute the rules to retrieve from grammar"
      ]
    },
    {
      "metadata": {
        "id": "Wb-NWr6X3AxO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mutate_rules(rule_list_1, rule_list_2):\n",
        "    pairs = list(product(rule_list_1, rule_list_2))\n",
        "    rules = []\n",
        "    for c_1, c_2 in pairs:\n",
        "        #print([(rule, prob) for rule, prob in cfg_rule_prob.items() if ' {} {} '.format(*[c_1.parent, c_2.parent]) in rule])\n",
        "        dummy = [rules.append(Rule('NT', rule.split(' --> ')[0], c_1, c_2, c_1.prob*c_2.prob*prob)) for rule, prob in cfg_rule_prob.items() if ' {} {} '.format(*[c_1.parent, c_2.parent]) in rule]\n",
        "        \n",
        "    return rules\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6RQoPz_I7dD8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This function generates the boxes to consider to permute tags\n",
        "def generate_boxes(x):\n",
        "    num_pairs = abs(x[0] - x[1])\n",
        "    offsets = [[0, num_pairs], [-1, 0]]\n",
        "    box_pairs = []\n",
        "    for i in range(num_pairs):\n",
        "        box_pairs.append([tuple(sum(y) for y in zip(x, offsets[0])), tuple(sum(y) for y in zip(x, offsets[1]))])\n",
        "        offsets[0][1] -= 1\n",
        "        offsets[1][0] -= 1\n",
        "        \n",
        "    return box_pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3fx0EnaD1wxx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Core Parser"
      ]
    },
    {
      "metadata": {
        "id": "qOH-FWPbFDFA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def print_recurse_tree(rule, depth):\n",
        "    if rule.rule_type == 'T':\n",
        "        for i in range(depth):\n",
        "            print('\\t', end = '')\n",
        "        print(rule.parent + ' - ' + rule.child_1)\n",
        "        return rule.parent\n",
        "    \n",
        "    for i in range(depth):\n",
        "        print('\\t', end = '')\n",
        "        \n",
        "    print('(' + rule.parent)\n",
        "    to_be_returned = print_recurse_tree(rule.child_2, depth + 1) + ' ' + print_recurse_tree(rule.child_1, depth + 1)\n",
        "    \n",
        "    for i in range(depth):\n",
        "        print('\\t', end = '')\n",
        "    print(')')\n",
        "    return to_be_returned\n",
        "\n",
        "\n",
        "# Deprecated\n",
        "def print_tree_bracs(rule):\n",
        "    global str_tree\n",
        "    if rule.rule_type == 'T':\n",
        "        str_tree += '(' + rule.parent + ' ' + rule.child_1 + ')'\n",
        "        return\n",
        "        \n",
        "    \n",
        "    str_tree+='(' + rule.parent + ' '\n",
        "    print_tree_bracs(rule.child_2), print_tree_bracs(rule.child_1)\n",
        "    str_tree+=')'\n",
        "    \n",
        "\n",
        "def print_tree(rule):\n",
        "    global str_tree\n",
        "    if rule.rule_type == 'T':\n",
        "        str_tree += rule.parent + ' '\n",
        "        return\n",
        "        \n",
        "    \n",
        "    print_tree(rule.child_2), print_tree(rule.child_1)\n",
        "    \n",
        "\n",
        "def parse_tree(sentence):\n",
        "    sent_words = sentence.split(' ')\n",
        "    parse = [[[] for x in range(y + 1)] for y in range(len(sent_words))]\n",
        "\n",
        "    for i, w in enumerate(sent_words):\n",
        "        if w not in vocab:\n",
        "            for i_ in range(3):\n",
        "                pos, prob_ = generate_leaf_rule()\n",
        "                parse[i][i] += [Rule('T', pos, w, None, prob_)]\n",
        "        else:\n",
        "            parse[i][i] += [Rule('T', rule.split(' --> ')[0], rule.split(' --> ')[1], None, prob) for rule, prob in leaf_rule_prob.items() if rule.split(' --> ')[1] == w]\n",
        "\n",
        "    for i in range(1, len(sent_words)):\n",
        "        for j in range(len(sent_words) - i):\n",
        "            this_box_rules = []\n",
        "            #print('{}, {}'.format(*[i + j, j]))\n",
        "            for boxes in generate_boxes([i + j, j]):\n",
        "                box_1 = boxes[0]\n",
        "                box_2 = boxes[1]\n",
        "                this_box_rules += mutate_rules(parse[box_1[0]][box_1[1]], parse[box_2[0]][box_2[1]])\n",
        "                #print(len(mutate_rules(parse[box_1[0]][box_1[1]], parse[box_2[0]][box_2[1]])))\n",
        "                try:\n",
        "                    pass\n",
        "                    #print(vars(this_box_rules[-1]))\n",
        "\n",
        "                except:\n",
        "                    pass\n",
        "        \n",
        "            parse[i + j][j] += sorted(this_box_rules, key = lambda x:x.prob)[:5]\n",
        "            \n",
        "    global str_tree\n",
        "    str_tree = ''\n",
        "    try:\n",
        "        print_tree(parse[-1][0][[x.prob for x in parse[-1][0]].index(max([x.prob for x in parse[-1][0]]))])\n",
        "        return str_tree, parse[-1][0][[x.prob for x in parse[-1][0]].index(max([x.prob for x in parse[-1][0]]))] #.replace(')(', ') (')\n",
        "    except:\n",
        "        return 'Parsing failed, Here are the boxes to debug!', parse\n",
        "\n",
        "\n",
        "#parse_tree('that package now sells for about 2,099 *U*')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gl1PPwp_3OaG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Parse here"
      ]
    },
    {
      "metadata": {
        "id": "v7P1lRWL0lNu",
        "colab_type": "code",
        "outputId": "a5f4cab2-5730-4db7-9893-267d9de9b767",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "the_parse, root = parse_tree(\"I am a man of my words\") # Experiment sentences here\n",
        "print(the_parse)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NP VBP JJ NN IN PRP$ NNS \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LsJv8W5P6wHE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "ca547e37-f62e-45a9-e3ee-9cfd4141f801"
      },
      "cell_type": "code",
      "source": [
        "print_recurse_tree(root, 1)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t(VP\n",
            "\t\t(VP\n",
            "\t\t\t(VP\n",
            "\t\t\t\tNP - I\n",
            "\t\t\t\tVBP - am\n",
            "\t\t\t)\n",
            "\t\t\tJJ - a\n",
            "\t\t)\n",
            "\t\t(VP\n",
            "\t\t\t(NP\n",
            "\t\t\t\t(NP\n",
            "\t\t\t\t\tNN - man\n",
            "\t\t\t\t\tIN - of\n",
            "\t\t\t\t)\n",
            "\t\t\t\tPRP$ - my\n",
            "\t\t\t)\n",
            "\t\t\tNNS - words\n",
            "\t\t)\n",
            "\t)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NP VBP JJ NN IN PRP$ NNS'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "D_vDqeTj6Qfo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d6e9f085-4287-48dc-a244-9130c102628a"
      },
      "cell_type": "code",
      "source": [
        "str_tree = ''\n",
        "print_tree_bracs(root)\n",
        "str_tree"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(VP (VP (VP (NP I)(VBP am))(JJ a))(VP (NP (NP (NN man)(IN of))(PRP$ my))(NNS words)))'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "id": "5f5XxTBA8E5l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Generate Latex qtree code"
      ]
    },
    {
      "metadata": {
        "id": "HX7rjAI27KsR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "outputId": "c3b638ac-765c-4823-a52e-c247b340f505"
      },
      "cell_type": "code",
      "source": [
        "my_tree = nltk.tree.Tree.fromstring(str_tree)\n",
        "my_tree.pformat_latex_qtree()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\\\Tree [.VP\\n        [.VP [.VP [.NP I ] [.VBP am ] ] [.JJ a ] ]\\n        [.VP\\n          [.NP [.NP [.NN man ] [.IN of ] ] [.PRP\\\\$ my ] ]\\n          [.NNS words ] ] ]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "id": "rxVZqlcS55OC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ]
    },
    {
      "metadata": {
        "id": "bC6DSH432qFn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_parse = []\n",
        "for i in range(len(test)):\n",
        "    try:\n",
        "        if len(test[i].leaves()) > 25:\n",
        "            continue\n",
        "        curr_parse = parse_tree(' '.join(test[i].leaves()).lower()).split(' ')[:-1]\n",
        "        print('{} over'.format(*[i]))\n",
        "        test_parse.append((i, curr_parse))\n",
        "        \n",
        "    except KeyboardInterrupt:\n",
        "        break\n",
        "        \n",
        "    except:\n",
        "        print('Throwed error at i = ' + str(i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WLNPGT13tKuM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_true = []\n",
        "test_pred = []\n",
        "for i, par in test_parse:\n",
        "    test_true.append([x[1] for x in test[i].pos()])\n",
        "    test_pred.append(par)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F4tOaEFNUQiD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_true, test_pred = sum(test_true, []), sum(test_pred, [])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3wsBItVuUSrn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score, average_precision_score, precision_score, f1_score\n",
        "print('Precision, Recall, F1 Score')\n",
        "precision_score(test_true, test_pred, average = 'macro'), recall_score(test_true, test_pred, average = 'macro'), f1_score(test_true, test_pred, average = 'macro')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}